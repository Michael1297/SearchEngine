# SearchEngine

Search engine on c++ (graduation work)

# TODO
 * Изучение [REST API](https://plape.medium.com/using-boost-and-served-libraries-to-build-a-c-rest-api-service-449aeebe6509) ?
  Требуется для отправки запросов с сайта в программу
 
 * Запускать в отдельных потоках индексацию каждого из разделов, перечисленных
в конфигурационном файле.\
 Нужно чтение из файла ссылок на страницы сайтов.\
 Нужна многопоточность - сколько страниц - столько и потоков.

* Получать HTML-код очередной страницы (сначала главной).
 Здесь нужен Curl и get/html запрос.

* Извлекать из него текстовые блоки информации. Это можно делать с помощью
библиотеки gumbo-parser.
- Подключить библиотеку.

* Извлекать из страницы все ссылки на страницы того же сайта и добавлять в очередь, проверив предварительно, не была ли какая-то из этих страниц уже проиндексирована через запрос к базе данных (таблица page).\
 Здесь нужны запросы к БД\
 Создать БД\
 использовать MySQL ?

* Полученные текстовые блоки разбивать на отдельные слова.
- Используем gumbo-parser или пишем скрипт разбивки сами

* Каждое слово преобразовывать в нормальную форму (см. ниже раздел
«Нормализация слов»).
- Изучить нормализацию слов

* Собирать все уникальные слова для данной страницы и считать их количества.
- Парсим сами. Проверить gumbo parser на возможность делать это удобнее.

* Если слово отсутствует в базе, добавлять его в таблицу word со значением
frequency, равным 1.\
 Если присутствует, увеличивать число frequency на 1.\
 Число frequency должно соответствовать количеству страниц, на которых слово встречается хотя бы один раз.\
- Работа с БД

* Добавлять связку слова и страницы, на которой она встречается, в таблицу search_index со значением rank, равным количеству упоминаний на странице.
- Работа с БД

* Переходить снова к пункту 2, если на текущей странице остались
непроиндексированные ссылки.
- Используем цикл для проверки всех ссылок

* Некоторые ссылки могут вести на несуществующие страницы (код ответа — 404) или страницы, содержащие ошибки (код ответа — 500).\
 Такие страницы также необходимо добавлять в таблицу page, но не индексировать
- Используем Curl и коды ответов на GET запросы.

# Minimal required build settings:
* cmake 3.20
* mingw 9.0 64-bit
* C++ 17
* MySQL 8.0
* MySQL Connector ODBC 8.0

# Checklist:
- [ ] Реализован метод /api/startIndexing.

- [ ] Индексация страниц происходит в фоновом режиме.

- [ ] Страницы при индексации обходятся рекурсивно.

- [ ] Одна и та же страница не индексируется два раза.

- [ ] HTML-теги не индексируются.

- [ ] Слова при индексации приводятся к нормальной форме при помощи стемминга.

- [ ] Для слов на странице рассчитывается их ранг по формуле.

- [ ] Реализован метод /api/search.

- [ ] Для каждой страницы в результате рассчитана её релевантность по формуле.

- [ ] Поиск возвращает результаты в порядке их релевантности.

- [ ] Метод поиска учитывает параметры limit и offset.

- [ ] Метод поиска возвращает общее количество результатов

- [ ] Найденные слова выделяются в сниппетах тегами \<b\>.

- [ ] Параметры для подключения к базе данных хранятся в конфигурационном файле

- [ ] Если в базе данных нет таблиц, они создаются автоматически при старте приложения.

- [ ] Проект выложен на GitHub со всеми необходимыми файлами для сборки.

- [ ] В README описана команда, которой необходимо запускать приложение после сборки.
